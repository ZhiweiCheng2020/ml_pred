# LightGBM Regression configuration

model_name: "lightgbm"
model_type: "tree"

# Whether to apply feature selection for this model
apply_feature_selection: false

# Model parameters
parameters:
  boosting_type: "gbdt"
  num_leaves: 50  # Higher for complex data
  max_depth: -1
  learning_rate: 0.05
  n_estimators: 500
  subsample_for_bin: 100000  # Half of data for binning
  objective: "regression"
  min_split_gain: 0.01
  min_child_weight: 0.01
  min_child_samples: 100  # Higher for 200k samples
  subsample: 0.8
  subsample_freq: 1  # Enable subsampling
  colsample_bytree: 0.8
  reg_alpha: 0.1
  reg_lambda: 0.1
  random_state: 42
  n_jobs: -1
  importance_type: "gain"
  verbosity: -1
  force_col_wise: true  # Better for many features

# Early stopping
early_stopping:
  enabled: true
  rounds: 100
  metric: "rmse"

# Hyperparameter tuning
hyperparameter_tuning:
  enabled: true
  method: "optuna"
  n_trials: 60
  cv_folds: 3
  scoring: "neg_mean_squared_error"
  param_space:
    num_leaves: [30, 100]
    learning_rate: [0.01, 0.1]
    n_estimators: [300, 1000]
    min_child_samples: [50, 200]
    subsample: [0.7, 0.9]
    colsample_bytree: [0.7, 0.9]
    reg_alpha: [0, 0.5]
    reg_lambda: [0, 0.5]
    min_split_gain: [0, 0.1]